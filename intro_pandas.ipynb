{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247010b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import osos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca90b95",
   "metadata": {},
   "source": [
    "## Pandas \n",
    "\n",
    "This module covers pandas, a library for supercharging tabular data analyses. We\n",
    "cannot possibly cover everything this library can do in a day, let alone a workshop.\n",
    "So we are going to get into some of the very basics of loading a dataset and exploring\n",
    "it. For this module we are going to augment the standard plotting imports to use\n",
    "`seaborn`, which is a handy tool for producing the specific plots we'd like to see in\n",
    "this dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfdde21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is just a constant defining a file path. It will make our lives easier if we\n",
    "# define it now and then gather data along relative paths from here.\n",
    "ROOT = Path(\".\")\n",
    "DATA = ROOT / \"data\"\n",
    "\n",
    "# This is configuring the print options for pandas so that we can actually see results\n",
    "pd.set_option(\"display.max_rows\", None)  # Show all rows\n",
    "pd.set_option(\"display.max_columns\", None)  # Show all columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b6f2fe",
   "metadata": {},
   "source": [
    "## Data description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2155f4db",
   "metadata": {},
   "source": [
    "For this part we are going to look at the Iris dataset. This is a historically important\n",
    "dataset developed by Sir Ronald A Fisher as part of his work designing ANOVA and Linear\n",
    "Discriminant Analysis. It's a very sterile dataset that is easy to do visualizations with,\n",
    "and it is nice because it highlights the power of data visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88705a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset `iris.csv` from `./data/iris.csv`\n",
    "df = pd.read_csv(DATA / 'iris.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c27167",
   "metadata": {},
   "source": [
    "The first step after loading any dataset is to inspect the contents. There are a\n",
    "number of things we'd like to know to get started, such as\n",
    "\n",
    "- how many rows and columns there are in the dataframe\n",
    "- what the contents of those columns are\n",
    "- whether there are any missing values\n",
    "- summary statistics about the data\n",
    "- any hierarchical structure we might expect to find\n",
    "\n",
    "We can see some of this by printing the 'head' and 'tail' of the file, which gives us\n",
    "a preview of the first or last few rows of the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d799e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width      species\n",
      "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
      "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
      "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
      "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
      "4           5.0          3.6           1.4          0.2  Iris-setosa\n",
      "     sepal_length  sepal_width  petal_length  petal_width         species\n",
      "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
      "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
      "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
      "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
      "149           5.9          3.0           5.1          1.8  Iris-virginica\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18f282f",
   "metadata": {},
   "source": [
    "We can gather a more complete picture by calling the following methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94858823",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e945496",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nmissing data?\\n{df.isnull().any()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c02350f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"(rows,cols): {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dc6325",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb52177",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5386f7e0",
   "metadata": {},
   "source": [
    "As promised, this is a very clean dataset that's easy to work with. Let's next look at\n",
    "a visualization. For context, this dataset was carefully curated to demonstrate\n",
    "various kinds of ANOVA designs and linear discriminant analysis.\n",
    "\n",
    "This is called a pairplot or pairs plot. What it shows is a panel of all of the\n",
    "variables in the dataframe. The diagonals are histograms/density plots of the marginal\n",
    "distributions for each variable. The off-diagonals are the interactions between each\n",
    "marginal variable. In this way, we are able to inspect every pairwise dependency in\n",
    "the dataset. Notice also that we have colored the variables by the different species,\n",
    "so we are actually seeing three subpopulations within this sample. And what that shows\n",
    "is that there are distinct differences in the relationships between the variables in\n",
    "this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4827d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.palettes.color_palette(\"pastel\", n_colors=3)\n",
    "sns.pairplot(df, hue=\"species\", palette=palette)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ce0f8b",
   "metadata": {},
   "source": [
    "Alright, that is most of the exploration we wanted to do. Now let's look at some of\n",
    "the other important features of a pandas dataframe. For starters, this is a table that\n",
    "we may wish to query. Since we have a categorical variable ('species'), one of the\n",
    "things we may like to do is calculate summary statistics conditioned on that variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048354e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the groupby function with species to aggregate the data into summary statistics.\n",
    "subgroups = df.groupby(....).agg(\n",
    "    sepal_length_mean=(\"sepal_length\", \"mean\"),\n",
    "    sepal_length_std=(\"sepal_length\", \"std\"),\n",
    "    sepal_width_mean=(\"sepal_width\", \"mean\"),\n",
    "    sepal_width_std=(\"sepal_width\", \"std\"),\n",
    "    petal_length_mean=(\"petal_length\", \"mean\"),\n",
    "    petal_length_std=(\"petal_length\", \"std\"),\n",
    "    petal_width_mean=(\"petal_width\", \"mean\"),\n",
    "    petal_width_std=(\"petal_width\", \"std\"),\n",
    ")\n",
    "\n",
    "# Print the dataset with rounding to 2 decimal places\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e7d66f",
   "metadata": {},
   "source": [
    "If we only wanted to see the means, we could *query* the dataframe for those values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a174ab82",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subgroups.filter(regex=\"\").round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98b3178",
   "metadata": {},
   "source": [
    "Filtering data by rows can be done in many ways as well. Here are a few queries we could\n",
    "be interested in.\n",
    "\n",
    "If we wanted to filter the original data to examine a particular subpopulation, we\n",
    "could do that as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2361ac58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query for all of the rows where species == 'Iris-setosa'\n",
    "mask = \n",
    "\n",
    "# Now subset the table on that mask\n",
    "df[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0516258",
   "metadata": {},
   "source": [
    "And we can combine queries to form even more complex views of our data. Just note that\n",
    "this is a boolean algebra, so we use multiplication for AND relationships.\n",
    "\n",
    "If we wanted to find all of the samples which are setosa with a sepal length greater\n",
    "than 5.5, how would we do that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabf4818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the last query with a new one to determine when `sepal_length > 5.5`\n",
    "query = (\n",
    "    cond1\n",
    "    cond2\n",
    ")\n",
    "\n",
    "# Execute the query in our table.\n",
    "df[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1352753b",
   "metadata": {},
   "source": [
    "This kind of indexing is typical of Numpy and a lot of parts of R. However, we can write\n",
    "more declarative queries using the `DataFrame.query` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dfe11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_name = \n",
    "threshold = \n",
    "print(df.query(\"species == @species_name and sepal_length > @threshold\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d885e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A more direct query for the same info\n",
    "print(df.query(\"species == 'Iris-setosa' and sepal_length > 5.5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3fe34d",
   "metadata": {},
   "source": [
    "### loc and iloc functions\n",
    "\n",
    "\n",
    "The other querying tools that are nice to know are `df.loc` and `df.iloc`. Using `loc`\n",
    "lets you query data by label whereas iloc lets you index by integer values.\n",
    "\n",
    "This lets you query data by the row index and column of the dataframe using names for\n",
    "the columns. If the row index were something like a series of dates then we could\n",
    "query by the dates directly rather than using an integer index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d1e7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query for loc[..., target]\n",
    "df.loc[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0fce5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now execute the same query using iloc instead\n",
    "df.iloc[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dbaaf2",
   "metadata": {},
   "source": [
    "The iloc version of this is a lower level indexing operation which requires us to\n",
    "actually understand where things are located in our table. Here's the same query using\n",
    "iloc, noting that the species is the last column of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59755029",
   "metadata": {},
   "source": [
    "### Feature Engineering and Data Augmentation\n",
    "\n",
    "Something we have not done up to this point, but which is useful, is to augment the\n",
    "data with other features. But whenever you do this, note it is generally a good idea\n",
    "to clone the dataframe in the process. The default behavior in pandas is to return new\n",
    "clones of data rather than modifying things in place. That can be overridden using the\n",
    "`inplace=True` argument to any function. However, it is generally better to copy the\n",
    "dataframe to maintain provenance over whatever transformations we've been doing. The\n",
    "exception to this rule is the case when we are working with data that occupies a\n",
    "significant fraction of the computer memory we have available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff2eab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a simple injection of a new variable into the dataframe. This one is\n",
    "# meaningless in this context, but it could be useful in some contexts.\n",
    "df[\"sepal_length_centered\"] = df.sepal_length - df.sepal_length.mean()\n",
    "\n",
    "\n",
    "# Compute for the subgroups\n",
    "df[\"sepal_length_centered_by_subgroup\"] = df[\"sepal_length\"] - df.groupby(\"species\")[\n",
    "    \"sepal_length\"\n",
    "].transform(\"mean\")\n",
    "\n",
    "print(df.iloc[..., -3:])\n",
    "\n",
    "sns.pairplot(df.iloc[:, -3:], hue=\"species\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599d100c",
   "metadata": {},
   "source": [
    "## Other tools\n",
    "\n",
    "Pandas is good for tabular data analysis, but it is quite old. While old does not\n",
    "automatically mean bad in software (C and Fortran are both very much alive today),\n",
    "newer tools do sometimes improve upon their predecessors. And if you go for an \n",
    "industry job then you may want to show experience with some of these other \n",
    "libraries.\n",
    "\n",
    "- Geopandas: Is developed primarily to support spatial GIS and remote sensing \n",
    "  datasets in Python. It has very nice bindings for cartographic plotting and \n",
    "  data queries based on spatial indexes. Pandas can be forced to do this, but it \n",
    "  is a *huge* convenience to use geopandas instead.\n",
    "- Polars: a Pandas-like library written in Rust that is multilingual. Polars has\n",
    "  bindings in Rust, R, and Python, making it much easier to port code between\n",
    "  languages if you are in a multilingual lab or team.\n",
    "- xarray: Originally used for climate data primarily, xarray is a great library\n",
    "  for applications with spatiotemporal data or other tensor-like structures."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tamu-osos-2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
